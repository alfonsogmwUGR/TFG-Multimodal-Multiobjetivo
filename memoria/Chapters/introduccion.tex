\chapter{Introducción}\label{ch:intro}


Vivimos en un mundo de datos. Cada minuto, cada segundo, se generan y almacenan cantidades masivas de datos en internet, en las redes sociales y en bases de datos de todo el mundo. Y no solo eso, sino que además la cantidad de datos que se crean es cada vez mayor: con la aparición del Internet de las Cosas (\emph{Internet of Things}), la generación de nuevos datos ha experimentado una gran aceleración gracias a fuentes de datos tan cotidianos como teléfonos móbiles, cámaras, micrófonos, sensores biométricos, etc. Al ritmo actual, se estima que en el año 2025 existirán un total de 163 zettabytes de datos en todo el mundo \cite{reinsel2017data}.

Por todo ello, las técnicas de minería de datos han cobrado una especial relevancia en los últimos años, ya que pueden resultar muy útiles para extraer patrones e información valiosa de las bases de datos masivas. Un cierto tipo de algoritmos, los llamados algoritmos de aprendizaje automático, constituyen toda una rama de la inteligencia artificial y tienen la particularidad de que son capaces de aprender a partir de  datos que reciben como entrada, por lo que resultan idóneos para aprovechar todos esos datos. La primera vez que se habló del concepto de \emph{aprendizaje automático} (originalmente \emph{machine learning}) se remonta al 1959, año en que Arthur Samuel, por aquel entonces investigador de IBM y pionero de la inteligencia artificial, acuñó el término \cite{samuel1959some}. Desde entonces, han surgido numerosas definiciones de lo que es el aprendizaje automático. Una definición bastante formal y de las más usadas a la hora de referirse a los algoritmos de aprendizaje quizá sea la siguiente: <<Un programa se dice que aprende de la experiencia $E$ con respecto a una clase de tareas $T$ y una medida de rendimiento $P$ si su rendimiento en la tarea $T$, medida con $P$, mejora con la experiencia $E$.>>\cite{mitchell1997machine}


Tradicionalmente, las técnicas de aprendizaje automático se han agrupado en tres grandes categorías \cite{abu2012learning}:
\begin{itemize}
	\item \textbf{Aprendizaje supervisado}. En este tipo de aprendizaje, los datos de entrenamiento (es decir, los datos usados para que el modelo \emph{aprenda}) contienen ejemplos explícitos de cuáles serían las etiquetas o valores de salida (\emph{outputs}) correctos. Un buen ejemplo de este enfoque sería la clasificación de imágenes con dígitos escritos a mano, donde es posible asignar a cada imagen una etiqueta para indicarle al modelo a qué dígito del $0$ al $9$ corresponde. Este tipo de problema se conoce como clasificación, el cual, junto al problema de la regresión, constituye la variante más típica del aprendizaje supervisado.
	\item \textbf{Aprendizaje no supervisado}. En este enfoque, los datos de entrenamiento no contienen ninguna información de salida, tan solo se dispone de datos no etiquetados. Aún sin esa información, es posible extraer información de los datos, encontrando patrones, agrupaciones o estructuras intrínsecos en ellos, por medio de técnicas como el \emph{clustering}, que más adelante se verá con detalle.
	\item \textbf{Aprendizaje por refuerzo}. Al igual que en el aprendizaje no supervisado, en el aprendizaje por refuerzo tampoco se dispone de información explícita que indique cuál es la salida correcta. En su lugar, por cada salida dada por el modelo se dispone de un grado de bondad de esa salida obtenida, de modo que es posible saber cómo de buena ha sido. De esta forma, el modelo es capaz de ajustarse por sí solo sucesivas veces hasta obtener el mejor grado de bondad posible.
\end{itemize}

Además de estas tres, existe una cuarta categoría adicional llamada \textbf{aprendizaje semisupervisado}, que, simplificando en exceso, consiste en un híbrido entre el aprendizaje supervisado y el no supervisado. De esta nueva categoría forma parte lo que se conoce como \emph{clustering con restricciones}, una variante del clustering convencional en la que se introduce algo de conocimiento sobre la solución óptima (es decir, la solución verdadera) en forma de restricciones que se deben satisfacer. Todos estos conceptos se estudiarán con mayor profundidad más adelante.

También se verá que tanto el problema del clustering clásico como el del clustering con restricciones pueden ser enfocados como un problema de optimización convencional. Y de hecho, también pueden formularse como problemas de optimización con más de una función objetivo a minimizar o maximizar, lo que se conoce como \emph{optimización multiobjetivo}.

Como tales, para resolverlos pueden utilizarse los llamados \emph{algoritmos evolutivos}, un tipo de algoritmos de optimización aproximativa inspirados en la biología y la evolucion de las especies. De ellos, aquellos que son capaces de lidiar con la optimización multiobjetivo reciben el nombre de \emph{algoritmos evolutivos multiobjetivo}. Una clase concreta de este tipo de algoritmos que han demostrado ser bastante prometedores son los algoritmos evolutivos multiobjetivo basados en descomposición, los cuales funcionan descomponiendo un problema de optimización multiobjetivo en varios subproblemas de optimización de un objetivo.

Más recientemente, han surgido variantes de estos algoritmos que son capaces de manejar la multimodalidad, un fenómeno que se da en los problemas de optimización cuando soluciones muy diferentes ofrecen resultados casi idénticos o de una calidad muy similar. En concreto, el método ADA, propuesto en 2019, es capaz de adaptar un algoritmo evolutivo multiobjetivo basado en descomposición para que sea capaz de afrontar problemas multimodales, aportando para ello un mecanismo para mantener la diversidad en el espacio de soluciones.

\section{Estructura y objetivos de este trabajo}

Este Trabajo de Fin de Grado tiene como objetivo aplicar distintas versiones de un algoritmo evolutivo multiobjetivo basado en descomposición modificado con ADA para resolver problemas de clustering con restricciones, los cuales presentan un alto grado de multimodalidad. No hay constancia de que se haya empleado ADA para resolver problemas de clustering con restricciones con anterioridad, por lo que, en este sentido, este trabajo será pionero.

La primera parte de este trabajo servirá para situar al lector en el contexto teórico del que forman parte tanto el problema a resolver como los métodos utilizados. Se presentarán los problemas del clustering clásico y el clustering con restricciones. Se explicará en qué consiste la optimización multiobjetivo y cuáles son sus particularidades frente a la optimización de un solo objetivo. Se hablará brevemente de los llamados algoritmos evolutivos y, más concretamente, de los algoritmos evolutivos multiobjetivo, para finalmente describir con detalle los algoritmos evolutivos multiobjetivo basados en descomposición: cuál es el algoritmo más conocido, cómo funciona la idea de \emph{descomposición}, cómo es posible introducir diversidad en el espacio de soluciones para afrontar la multimodalidad, cómo funciona exactamente ADA, etc.

En la segunda parte se describirá la experimentación seguida para este trabajo y se analizarán los resultados obtenidos. Se enumerarán los conjuntos de datos empleados y se describirá sus características. Se describirá la metodología seguida en el experimento, listando las variantes de ADA con las que se experimentará, así como los parámetros e hiperparámetros elegidos. También se hablará de la estructura del software desarrollado y de los detalles de la implementación de los algoritmos. Finalmente, se llevará a cabo un análisis estadístico de los resultados para determinar si las diferencias entre las distintas versiones de ADA usadas son significativas.




